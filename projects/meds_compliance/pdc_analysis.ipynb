{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medications Compliance workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook uses medication order and statements tables from the NEL primary care data to analyse medications compliance by expolring methods of proportion of days covered (PDC)\n",
    "\n",
    "See paper https://joppp.biomedcentral.com/articles/10.1186/s40545-021-00385-w\n",
    "\n",
    "Please check and install requirements.txt before proceeding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tableone import TableOne\n",
    "from word2number import w2n\n",
    "\n",
    "from phmlondon.snow_utils import SnowflakeConnection\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG and FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_classes(df, column_name, n=10):\n",
    "    \"\"\"\n",
    "    Get the top n most frequent values in a specified column of the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the data.\n",
    "        column_name (str): The name of the column to analyze.\n",
    "        n (int): The number of top values to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A series containing the top n most frequent values and their counts.\n",
    "    \"\"\"\n",
    "    return df[column_name].value_counts().head(n)\n",
    "\n",
    "def plot_top_classes(class_counts):\n",
    "    \"\"\"\n",
    "    Plot the top classes in a bar graph.\n",
    "\n",
    "    Args:\n",
    "        class_counts (pd.Series): A series containing the class counts.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    class_counts.plot(kind='bar', color='skyblue')\n",
    "\n",
    "    # Set the title and labels\n",
    "    plt.title('Top Most Frequent Classes', fontsize=16)\n",
    "    plt.xlabel('Class', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Adjust layout to fit everything\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def clean_dose(df):\n",
    "    \"\"\"Cleans the 'dose' column in a given DataFrame.\n",
    "    Args:\n",
    "        df: pandas DataFrame with columns called 'dose' and 'quantity'.\n",
    "    Returns:\n",
    "        DataFrame with an additional column 'tablets_per_day' and 'calculated_duration' and 'order_enddate'\n",
    "    \"\"\"\n",
    "\n",
    "    def process_dose(dose):\n",
    "        \"\"\"Clean the dose column and extract daily tablet count.\n",
    "        Args:\n",
    "            dose: A single dose entry (string).\n",
    "        Returns:\n",
    "            Calculated tablets per day or None.\n",
    "        \"\"\"\n",
    "        if not isinstance(dose, str):  # Handle cases where dose is NaN or not a string\n",
    "            return None\n",
    "\n",
    "        dose = dose.lower().strip()\n",
    "\n",
    "        # Frequency mapping dictionary\n",
    "        frequency_mapping = {\n",
    "            \"once\": 1,\n",
    "            \"twice\": 2,\n",
    "            \"three times\": 3,\n",
    "            \"four times\": 4,\n",
    "            \"daily\": 1,\n",
    "            \"per day\": 1,\n",
    "            \"every morning\": 1,\n",
    "            \"at night\": 1,\n",
    "            \"every evening\": 1,\n",
    "            \"morning\": 1,\n",
    "            \"night\": 1,\n",
    "            \"once a day\": 1,\n",
    "            \"twice a day\": 2,\n",
    "            \"three times a day\": 3,\n",
    "            \"four times a day\": 4,\n",
    "        }\n",
    "\n",
    "        # Extract frequency first\n",
    "        frequency_match = None\n",
    "        for phrase, frequency in frequency_mapping.items():\n",
    "            if phrase in dose:\n",
    "                frequency_match = frequency\n",
    "                break\n",
    "\n",
    "        if not frequency_match:\n",
    "            frequency_match = 1  # Default to once daily if no specific frequency found\n",
    "\n",
    "        # Extract tablet count (defaults to 1 if not found)\n",
    "        tablet_count = 1  # Default to 1\n",
    "        tablet_match = re.search(r'(\\d+|one|two|three|four|five|six|seven|eight|nine|ten)', dose)\n",
    "        if tablet_match:\n",
    "            tablet_count = tablet_match.group(1)\n",
    "            tablet_count = int(tablet_count) if tablet_count.isdigit() else w2n.word_to_num(tablet_count)\n",
    "\n",
    "        # Return daily tablets per day\n",
    "        return tablet_count * frequency_match if frequency_match else None\n",
    "\n",
    "    # Apply function to \"dose\" column\n",
    "    df[\"tablets_per_day\"] = df[\"dose\"].apply(process_dose)\n",
    "\n",
    "    # Now calculate the \"calculated_duration\" based on the quantity and tablets_per_day\n",
    "    df[\"calculated_duration\"] = df.apply(\n",
    "        lambda row: float(row[\"quantity_value\"]) / row[\"tablets_per_day\"] if (\n",
    "            row[\"tablets_per_day\"] and row[\"quantity_unit\"] and \n",
    "            re.search(r\"tablet(s)?|capsule(s)?\", row[\"quantity_unit\"], re.IGNORECASE)\n",
    "        ) else None, axis=1\n",
    "    )\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')\n",
    "\n",
    "    # Calculate 'order_enddate' by adding 'calculated_duration' or 'duration_days' to 'order_date'\n",
    "    df[\"order_enddate\"] = df[\"order_date\"] + pd.to_timedelta(df[\"calculated_duration\"].fillna(df[\"duration_days\"]), unit='D')\n",
    "\n",
    "    return df  # Return modified DataFrame\n",
    "\n",
    "def compare_durations_summary(comp_orders):\n",
    "    \"\"\"\n",
    "    Compare the 'duration_days' and 'calculated_duration' and flag the most accurate one.\n",
    "\n",
    "    Arguments:\n",
    "    comp_orders : DataFrame containing 'duration_days' and 'calculated_duration'\n",
    "\n",
    "    Returns:\n",
    "    summary_stats : Dictionary containing summary statistics of the comparisone\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate absolute difference between documented and calculated duration\n",
    "    comp_orders['abs_diff'] = (comp_orders['duration_days'] - comp_orders['calculated_duration']).abs()\n",
    "\n",
    "    # Calculate relative difference (relative to the max of the two values)\n",
    "    comp_orders['rel_diff'] = comp_orders['abs_diff'] / comp_orders[['duration_days', 'calculated_duration']].max(axis=1)\n",
    "\n",
    "    # Calculate percentage difference\n",
    "    comp_orders['perc_diff'] = (comp_orders['abs_diff'] / comp_orders['duration_days']) * 100\n",
    "\n",
    "    summary_stats = {\n",
    "        \"mean_abs_diff\": comp_orders['abs_diff'].mean(),\n",
    "        \"median_abs_diff\": comp_orders['abs_diff'].median(),\n",
    "        \"max_abs_diff\": comp_orders['abs_diff'].max(),\n",
    "        \"min_abs_diff\": comp_orders['abs_diff'].min(),\n",
    "        \"mean_perc_diff\": comp_orders['perc_diff'].mean(),\n",
    "        \"median_perc_diff\": comp_orders['perc_diff'].median(),\n",
    "        \"max_perc_diff\": comp_orders['perc_diff'].max(),\n",
    "        \"min_perc_diff\": comp_orders['perc_diff'].min(),\n",
    "        \"count_flag_calculated\": (comp_orders['abs_diff'] <= 5).sum(),  # Example flag where abs_diff <= 5\n",
    "        \"count_flag_documented\": (comp_orders['abs_diff'] > 5).sum(),  # Example flag where abs_diff > 5\n",
    "    }\n",
    "\n",
    "    return summary_stats\n",
    "\n",
    "\n",
    "\n",
    "def define_treatment_periods(df, gap_threshold=None):\n",
    "    \"\"\"\n",
    "    Assigns period IDs based on treatment gaps.\n",
    "\n",
    "    Arguments:\n",
    "        df : DataFrame containing prescription orders.\n",
    "        gap_threshold : Integer defining treatment gaps (default: uses order-specific duration_days).\n",
    "\n",
    "    Returns:\n",
    "        df : Updated DataFrame with 'period_id'.\n",
    "    \"\"\"\n",
    "\n",
    "    date_cols = [\"order_date\", \"order_enddate\"]\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Ensure gap_threshold is numeric\n",
    "    if gap_threshold is not None:\n",
    "        df[\"gap_value\"] = gap_threshold\n",
    "    else:\n",
    "        df[\"gap_value\"] = pd.to_numeric(df[\"calculated_duration\"].fillna(df[\"duration_days\"]), errors=\"coerce\")\n",
    "\n",
    "    # Sort & rank orders per Person & Drug\n",
    "    df = df.sort_values([\"person_id\", \"drug\", \"order_date\"])\n",
    "    df[\"order_rank\"] = df.groupby([\"person_id\", \"drug\"]).cumcount() + 1\n",
    "\n",
    "    # Compute Days to Next Order\n",
    "    df[\"next_order_date\"] = df.groupby([\"person_id\", \"drug\"])[\"order_date\"].shift(-1)\n",
    "    df[\"days_to_next_order\"] = (df[\"next_order_date\"] - df[\"order_enddate\"]).dt.days\n",
    "    df[\"days_to_next_order\"] = df[\"days_to_next_order\"].fillna(0).clip(lower=0)\n",
    "\n",
    "    # Identify New Treatment Periods\n",
    "    df[\"new_period_flag\"] = (df[\"days_to_next_order\"] > df[\"gap_value\"]).astype(int)\n",
    "    df[\"shifted_flag\"] = df.groupby([\"person_id\", \"drug\"])[\"new_period_flag\"].shift(1, fill_value=0)\n",
    "    df[\"period_id\"] = df.groupby([\"person_id\", \"drug\"])[\"shifted_flag\"].cumsum() + 1\n",
    "\n",
    "    # Exclude Last Gap in a Period (Represents Treatment Break)\n",
    "    df[\"days_to_next_order\"] = df[\"days_to_next_order\"].where(df[\"new_period_flag\"] != 1, 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def period_pdc(df):\n",
    "    \"\"\"\n",
    "    Summarises treatment periods per person and drug and calculates PDC.\n",
    "\n",
    "    Arguments:\n",
    "        df : DataFrame with period IDs assigned.\n",
    "\n",
    "    Returns:\n",
    "        period_summary : DataFrame summarising each period including a PDC calculation.\n",
    "    \"\"\"\n",
    "\n",
    "    period_summary = df.groupby([\"person_id\", \"drug\", \"period_id\"]).agg(\n",
    "        start_date=(\"order_date\", \"min\"),\n",
    "        end_date=(\"order_enddate\", \"max\"),\n",
    "        order_gaps=(\"days_to_next_order\", \"sum\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    period_summary[\"duration_period\"] = (period_summary[\"end_date\"] - period_summary[\"start_date\"]).dt.days\n",
    "\n",
    "    # Calculate Estimated PDC\n",
    "    period_summary[\"duration_orders\"] = period_summary[\"duration_period\"] - period_summary[\"order_gaps\"]\n",
    "    period_summary[\"est_pdc\"] = period_summary[\"duration_orders\"] / period_summary[\"duration_period\"]\n",
    "\n",
    "    # Avoid division by zero, return NaN instead of None\n",
    "    period_summary[\"est_pdc\"] = period_summary[\"est_pdc\"].where(period_summary[\"duration_period\"] > 0, float(\"nan\"))\n",
    "\n",
    "    return period_summary\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_orders(df):\n",
    "    \"\"\" Fills missing duration values and generates covered days for each order. \"\"\"\n",
    "    df['days_supply'] = df['calculated_duration'].fillna(df['duration_days']).fillna(0).astype(int)  # Ensures no NaNs\n",
    "\n",
    "    # Expand covered days\n",
    "    df['covered_days'] = df.apply(lambda row: pd.date_range(row['order_date'], periods=row['days_supply']), axis=1)\n",
    "\n",
    "    # Explode into individual covered days & reset index\n",
    "    return df.explode('covered_days', ignore_index=True)[['person_id', 'drug', 'covered_days']]\n",
    "\n",
    "def compute_pdc(df, start_date, end_date):\n",
    "    \"\"\" Computes PDC for a given time window. \"\"\"\n",
    "    total_days = (end_date - start_date).days + 1\n",
    "    covered_days = df[(df['covered_days'] >= start_date) & (df['covered_days'] <= end_date)]['covered_days'].nunique()\n",
    "    return covered_days / total_days if total_days > 0 else 0\n",
    "\n",
    "def calculate_moving_pdc(df, window_size='12M', step_size='1M'):\n",
    "    \"\"\" Calculates moving window PDC for all patients & drugs. \"\"\"\n",
    "    results = []\n",
    "    patients_drugs = df[['person_id', 'drug']].drop_duplicates()\n",
    "\n",
    "    for _, row in patients_drugs.iterrows():\n",
    "        patient, drug = row['person_id'], row['drug']\n",
    "        subset = df[(df['person_id'] == patient) & (df['drug'] == drug)]\n",
    "\n",
    "        # Define time range\n",
    "        min_date, max_date = subset['covered_days'].min(), subset['covered_days'].max()\n",
    "        start_dates = pd.date_range(start=min_date, end=max_date, freq=step_size)\n",
    "\n",
    "        for start in start_dates:\n",
    "            end = start + pd.DateOffset(months=int(window_size[:-1])) - pd.Timedelta(days=1)\n",
    "            pdc = compute_pdc(subset, start, end)\n",
    "            results.append({'person_id': patient, 'drug': drug, 'start_window': start, 'end_window': end, 'PDC': pdc})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pdc_trend(df_patient):\n",
    "    \"\"\"\n",
    "    Plots PDC over time for a patient, showing each drug's trend on the same graph.\n",
    "    Takes only the patient-specific dataframe.\n",
    "    \"\"\"\n",
    "    # Get the unique drugs for this patient\n",
    "    unique_drugs = df_patient['drug'].unique()\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Loop through each drug and plot the PDC trend with different colors\n",
    "    for idx, drug in enumerate(unique_drugs):\n",
    "        drug_pdc = df_patient[df_patient['drug'] == drug]\n",
    "        plt.plot(drug_pdc['start_window'], drug_pdc['PDC'], marker='o', linestyle='-', label=drug, color=plt.cm.tab10(idx % 10))  \n",
    "\n",
    "    # Get the earliest start_date and latest end_date for the patient (across all drugs)\n",
    "    overall_start_date = df_patient['start_date'].min()\n",
    "    overall_end_date = df_patient['end_date'].max()\n",
    "\n",
    "    # Add vertical dashed red lines for start and end dates\n",
    "    plt.axvline(x=overall_start_date, color='red', linestyle='--', label=f'Start Date: {overall_start_date.date()}')\n",
    "    plt.axvline(x=overall_end_date, color='red', linestyle='--', label=f'End Date: {overall_end_date.date()}')\n",
    "\n",
    "    # Title with drug names\n",
    "    drug_names_str = ', '.join(unique_drugs)  \n",
    "    plt.title(f'PDC Over Time for Patient {df_patient[\"person_id\"].iloc[0]} - Drugs: {drug_names_str}')\n",
    "\n",
    "    # Labels and Formatting\n",
    "    plt.xlabel('Time (Start Window)')\n",
    "    plt.ylabel('Proportion of Days Covered (PDC)')\n",
    "    plt.legend(title='Drugs', loc='upper left', bbox_to_anchor=(1,1))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def poi_analysis(df, start_poi, end_poi, window_size='12M', step_size='1M'):\n",
    "    \"\"\"\n",
    "    Filters the data based on a given Period of Interest (POI) and computes PDC for that period.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The original dataframe containing medication order data.\n",
    "    - start_poi: Start date of the period of interest (e.g., '2024-01-01').\n",
    "    - end_poi: End date of the period of interest (e.g., '2024-12-31').\n",
    "    - window_size: Window size for moving PDC calculation (e.g., '12M').\n",
    "    - step_size: Step size for the moving window (e.g., '1M').\n",
    "\n",
    "    Returns:\n",
    "    - pdc_df: DataFrame with moving window PDC calculations, including first and last order dates for each person_drug combination.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert start_poi and end_poi to datetime if they are not already\n",
    "    start_poi = pd.to_datetime(start_poi)\n",
    "    end_poi = pd.to_datetime(end_poi)\n",
    "\n",
    "    # Step 1: Preprocess the orders to generate 'covered_days'\n",
    "    covered_days_df = preprocess_orders(df)\n",
    "\n",
    "    # Step 2: Filter the data based on the POI\n",
    "    df_poi = covered_days_df[(covered_days_df['covered_days'] >= start_poi) & (covered_days_df['covered_days'] <= end_poi)]\n",
    "\n",
    "    # Step 3: Calculate the moving window PDC for the filtered period\n",
    "    pdc_df = calculate_moving_pdc(df_poi, window_size=window_size, step_size=step_size)\n",
    "\n",
    "    # Step 4: Get first and last order dates for each person_drug combo\n",
    "    first_last_order_dates = df.groupby(['person_id', 'drug']).agg(\n",
    "        start_date=('order_date', 'min'),\n",
    "        end_date = ('order_enddate', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Step 5: Merge first and last order dates with the PDC data\n",
    "    pdc_df = pdc_df.merge(first_last_order_dates, on=['person_id', 'drug'], how='left')\n",
    "\n",
    "    return pdc_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(snowsesh, class_1, class_2, class_3):\n",
    "    \"\"\"\n",
    "    Retrieves dataset.\n",
    "\n",
    "    Args:\n",
    "        snowsesh (object): Database session object for executing queries.\n",
    "        class_1 (str): First class to filter by.\n",
    "        class_2 (str): Second class to filter by.\n",
    "        class_3 (str): Third class to filter by.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The retrieved dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    chosen_classes = [class_1, class_2, class_3]\n",
    "    classes_condition = \", \".join(f\"'{cls}'\" for cls in chosen_classes)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        o.id AS order_id,\n",
    "        o.person_id,\n",
    "        o.medication_statement_id,\n",
    "        d.order_name AS concept_name,\n",
    "        c.name,\n",
    "        d.drug,\n",
    "        o.dose,\n",
    "        o.quantity_value,\n",
    "        o.quantity_unit,\n",
    "        d.class,\n",
    "        d.core_concept_id,\n",
    "        o.core_concept_id AS concept,\n",
    "        o.clinical_effective_date AS order_date,\n",
    "        o.duration_days,\n",
    "        s.clinical_effective_date AS statement_date,\n",
    "        s.cancellation_date AS statement_enddate\n",
    "    FROM\n",
    "        prod_dwh.analyst_primary_care.medication_order o\n",
    "    LEFT JOIN\n",
    "        intelligence_dev.ai_centre_dev.drug_table_v3 d\n",
    "        ON d.core_concept_id = o.core_concept_id\n",
    "    LEFT JOIN\n",
    "        prod_dwh.analyst_primary_care.concept c\n",
    "        ON c.dbid = o.core_concept_id\n",
    "    LEFT JOIN\n",
    "        prod_dwh.analyst_primary_care.medication_statement s\n",
    "        ON s.id = o.medication_statement_id\n",
    "    WHERE d.class IN ({classes_condition})\n",
    "    LIMIT 100000;\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = snowsesh.execute_query_to_df(query)\n",
    "        df.columns = df.columns.str.lower()\n",
    "        print(f\"Retrieved {len(df)} rows with columns: {list(df.columns)}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving modeling data: {e}\")\n",
    "        raise\n",
    "\n",
    "def add_demographic_data(snowsesh, df, join_col=\"person_id\"):\n",
    "\n",
    "    \"\"\" Bring in the dempgraphics table and joins to the current table\n",
    "        Arguments:\n",
    "                  snowsesh:\n",
    "                    df = the dataframe oyu want to add demographic data to\n",
    "                      join_cols = what you ant the join to be on \n",
    "      \"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM intelligence_dev.ai_centre_feature_store.person_nel_master_index\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve demographic data\n",
    "        demo_df = snowsesh.execute_query_to_df(query)\n",
    "        demo_df.columns = demo_df.columns.str.lower()  # Ensure column names are lowercase\n",
    "\n",
    "        # Perform left join on person_id\n",
    "        merged_df = df.merge(demo_df, on=join_col, how=\"left\")\n",
    "\n",
    "        print(f\"Merged data: {len(merged_df)} rows with columns: {list(merged_df.columns)}\")\n",
    "        return merged_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving or merging demographic data: {e}\")\n",
    "        raise\n",
    "\n",
    "def match_closest_compliance_date(df, snowsesh):\n",
    "    \"\"\"\n",
    "    Fetches compliance data from Snowflake and matches each order to the closest compliance date.\n",
    "\n",
    "    Arguments:\n",
    "        df : DataFrame with prescription orders, containing 'person_id' and 'order_date'.\n",
    "        snowsesh : Active Snowflake connection.\n",
    "\n",
    "    Returns:\n",
    "        df : Updated with 'closest_compliance_date' and 'medication_compliance'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch compliance data from Snowflake\n",
    "    query = \"\"\"\n",
    "       SELECT DISTINCT person_id,\n",
    "                clinical_effective_date as compliance_date,\n",
    "                CASE\n",
    "                    WHEN core_concept_id = '119686' THEN 'good'\n",
    "                    WHEN core_concept_id = '239913' THEN 'poor'\n",
    "                END AS medication_compliance\n",
    "        FROM prod_dwh.analyst_primary_care.observation\n",
    "        WHERE core_concept_id IN ('119686', '239913')\n",
    "        ORDER BY person_id, compliance_date;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        compliance_df = snowsesh.execute_query_to_df(query)\n",
    "        compliance_df.columns = compliance_df.columns.str.lower()\n",
    "        print(f\"Retrieved {len(compliance_df)} rows with columns: {list(compliance_df.columns)}\")\n",
    "\n",
    "        # Ensure dates are in datetime format\n",
    "        df[\"start_date\"] = pd.to_datetime(df[\"start_date\"], errors=\"coerce\")\n",
    "        compliance_df[\"compliance_date\"] = pd.to_datetime(compliance_df[\"compliance_date\"], errors=\"coerce\")\n",
    "\n",
    "        # Merge compliance data (many-to-many merge)\n",
    "        merged_df = df.merge(compliance_df, on=\"person_id\", how=\"left\")\n",
    "\n",
    "        # Compute the absolute difference between start_date and compliance_date\n",
    "        merged_df[\"date_diff\"] = (merged_df[\"start_date\"] - merged_df[\"compliance_date\"]).abs()\n",
    "\n",
    "        # Drop rows with NaN in 'date_diff', since we can't compute the closest date for these\n",
    "        merged_df = merged_df.dropna(subset=[\"date_diff\"])\n",
    "\n",
    "        # Find the closest compliance date per order\n",
    "        closest_compliance = merged_df.loc[merged_df.groupby([\"person_id\", \"start_date\"])[\"date_diff\"].idxmin(), \n",
    "                                           [\"person_id\", \"start_date\", \"compliance_date\", \"medication_compliance\"]]\n",
    "\n",
    "        # Merge back to orders_df\n",
    "        df = df.merge(closest_compliance, on=[\"person_id\", \"start_date\"], how=\"left\")\n",
    "\n",
    "        # Rename for clarity\n",
    "        df.rename(columns={\"compliance_date\": \"closest_compliance_date\"}, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving modeling data: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY STATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table one, stratified by compliance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_one(df, stratification_col):\n",
    "    \"\"\"Creates a journal style 'tableone' with descriptive statistics\n",
    "    and appropriate tests for stratified data\"\"\"\n",
    "\n",
    "    categorical_vars = ['gender', 'ethnicity', 'imd_quintile', 'smoking_status', 'comorbidities']\n",
    "    continuous_vars = ['bmi_value', 'est_pdc']\n",
    "\n",
    "    table1 = TableOne(df, categorical=categorical_vars,\n",
    "                  continuous=continuous_vars,\n",
    "                  groupby= stratification_col,\n",
    "                  pval=True, missing=True)\n",
    "\n",
    "\n",
    "    print(table1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION and ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "snowsesh = SnowflakeConnection()\n",
    "snowsesh.use_database(\"INTELLIGENCE_DEV\")\n",
    "snowsesh.use_schema(\"AI_CENTRE_FEATURE_STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table with estimated PD per period. \n",
    "\n",
    "Period is defined by duration threshold.\n",
    "One row per period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(snowsesh,'Lipid-regulating drugs', 'Calcium-channel blockers','Angiotensin-converting enzyme inhibitors')\n",
    "df.head()\n",
    "#df.groupby(['person_id', 'drug']).size().reset_index(name='count').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_classes = get_top_n_classes(df, 'class', n=3)\n",
    "\n",
    "print(top_3_classes.head())\n",
    "\n",
    "plot_top_classes(top_3_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_dose(df)\n",
    "clean_df.head()\n",
    "\n",
    "#clean_df[clean_df['tablets_per_day'] != 1][['dose', 'quantity_value', 'duration_days', 'calculated_duration', 'tablets_per_day']].head(100)\n",
    "#clean_df[clean_df['duration_days'] != clean_df['calculated_duration']][['dose', 'order_date', 'quantity_value', 'duration_days', 'calculated_duration', 'tablets_per_day']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_durations_summary(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to sort the clean dose code and add the duration days calculation into the pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_data = define_treatment_periods(clean_df, gap_threshold=365)\n",
    "pdc_data = period_pdc(period_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(period_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdc_data.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add demographic data to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdc_demo_data = add_demographic_data(snowsesh, pdc_data)\n",
    "pdc_demo_comp_data = match_closest_compliance_date(pdc_demo_data, snowsesh)\n",
    "pdc_demo_data.groupby(['person_id', 'drug']).size().reset_index(name='count').shape[0]\n",
    "pdc_demo_comp_data.groupby(['person_id', 'drug']).size().reset_index(name='count').shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the key columns\n",
    "print(pdc_demo_data[['person_id', 'drug']].duplicated().sum())  # In the first dataset\n",
    "print(pdc_demo_comp_data[['person_id', 'drug']].duplicated().sum())  # In the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdc_demo_comp_data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table_one(pdc_demo_comp_data,'medication_compliance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDC moving window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your Period of Interest (POI)\n",
    "start_poi = '2020-01-01'\n",
    "end_poi = '2024-12-31'\n",
    "\n",
    "\n",
    "# Filter the data for a specific patient (e.g., patient with person_id = 6387610)\n",
    "patient_data = clean_df[clean_df['person_id'] == 51]\n",
    "print(patient_data.head())\n",
    "\n",
    "# Run the POI analysis for just this patient\n",
    "pdc_df_patient = poi_analysis(patient_data, start_poi=start_poi, end_poi=end_poi, window_size='6M', step_size='1M')\n",
    "print(pdc_df_patient.head())\n",
    "\n",
    "\n",
    "# Plot the PDC trend for this specific patient and drug\n",
    "plot_pdc_trend(pdc_df_patient)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
