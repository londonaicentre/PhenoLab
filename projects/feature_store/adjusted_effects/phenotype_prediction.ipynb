{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from phmlondon.snow_utils import SnowflakeConnection\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import logit\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHENOTYPES_OF_INTEREST = {\n",
    "    \"ASTHMA\": \"Asthma diagnoses simple reference set\",\n",
    "    \"COPD\": \"Chronic obstructive pulmonary disorder, emphysema, and associated lung diseases simple reference set\",\n",
    "    \"DIABETES_ANY\": \"Diabetes diagnoses simple reference set\",\n",
    "    \"DIABETES_T2\": \"Diabetes type 2 diagnoses simple reference set\",\n",
    "    \"DIABETES_T1\": \"Diabetes type 1 diagnoses simple reference set\",\n",
    "    \"HYPERTENSION\": \"Systemic hypertension diagnoses simple reference set\",\n",
    "    \"ANGINA_CHD\": \"Angina and coronary heart disease diagnoses simple reference set\",\n",
    "    \"MYOCARDIAL_INFARCTION\": \"Myocardial infarction diagnoses simple reference set\",\n",
    "    \"TIA\": \"Transient ischaemic attack diagnoses simple reference set\",\n",
    "    \"NON_HAEMORRHAGIC_STROKE\": \"Non haemorrhagic strokes simple reference set\",\n",
    "    \"CKD_1\": \"Chronic kidney disease 1\",\n",
    "    \"CKD_3\": \"Chronic kidney disease 3\",\n",
    "    \"DEPRESSION\": \"Depression diagnoses simple reference set\",\n",
    "    \"PSYCHOSIS_SCHIZOPHRENIA_BIPOLAR\": \"Psychosis, schizophrenia and bipolar affective disorder simple reference set\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(col):\n",
    "    \"\"\"\n",
    "    Clean column names for Patsy compatibility.\n",
    "    \"\"\"\n",
    "    return col.replace('-', '_minus_').replace('+', '_plus_').replace(' ', '_')\n",
    "\n",
    "def create_dummies(df, col, ref):\n",
    "    dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "    ref_col = f\"{col}_{ref}\"\n",
    "    if ref_col in dummies.columns:\n",
    "        dummies = dummies.drop(columns=[ref_col])\n",
    "    return dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modeling_data(\n",
    "        snowsesh,\n",
    "        phenotype_name\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Retrieves modeling dataset combining active patients and phenotype data.\n",
    "\n",
    "    Args:\n",
    "        snowsesh:\n",
    "            Snowflake session\n",
    "        phenotype_name:\n",
    "            The specific phenotype to analyse\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing features and phenotype flags for modeling\n",
    "    \"\"\"\n",
    "    # dynamic SQL to pull phenotype\n",
    "    if phenotype_name not in PHENOTYPES_OF_INTEREST:\n",
    "        raise ValueError(f\"Invalid phenotype name. Must be one of {list(PHENOTYPES_OF_INTEREST.keys())}\")\n",
    "    phenotype_db_name = PHENOTYPES_OF_INTEREST[phenotype_name]\n",
    "    phenotype_col = f'COALESCE(ph.\"{phenotype_db_name}\", 0) as \"{phenotype_name}\"'\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH age_categories AS (\n",
    "        SELECT\n",
    "            PERSON_ID,\n",
    "            CASE\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 18 THEN '0-17'\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 25 THEN '18-24'\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 35 THEN '25-34'\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 45 THEN '35-44'\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 55 THEN '45-54'\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 65 THEN '55-64'\n",
    "                WHEN DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) < 75 THEN '65-74'\n",
    "                ELSE '75+'\n",
    "            END as AGE_BAND,\n",
    "            DATEDIFF(year, DATE_OF_BIRTH, CURRENT_DATE()) as AGE_YEARS\n",
    "        FROM INTELLIGENCE_DEV.AI_CENTRE_FEATURE_STORE.PERSON_NEL_MASTER_INDEX\n",
    "    )\n",
    "    SELECT\n",
    "        -- Features\n",
    "        p.PERSON_ID,\n",
    "        p.PATIENT_LSOA_2011,\n",
    "        -- Use Other/Mixed/NotStated/Unknown as REFERENCE group\n",
    "        CASE\n",
    "            WHEN p.ETHNIC_AIC_CATEGORY IN ('Other', 'Not Stated', 'Mixed') THEN 'Unknown'\n",
    "            ELSE COALESCE(p.ETHNIC_AIC_CATEGORY, 'Unknown') -- fold into reference\n",
    "        END as ETHNIC_AIC_CATEGORY,\n",
    "        -- Use Female/Other as REFERENCE group\n",
    "        CASE\n",
    "            WHEN p.GENDER IN ('Male', 'Female') THEN p.GENDER\n",
    "            ELSE 'Female'  -- fold Other into reference\n",
    "        END as GENDER,\n",
    "        ac.AGE_BAND,\n",
    "        ac.AGE_YEARS,\n",
    "        -- Normalise IMD rank to 0-1 scale\n",
    "        CAST(p.LONDON_IMD_RANK as FLOAT) / (\n",
    "            SELECT MAX(LONDON_IMD_RANK)\n",
    "            FROM INTELLIGENCE_DEV.AI_CENTRE_FEATURE_STORE.PERSON_NEL_MASTER_INDEX\n",
    "        ) as NORMALISED_IMD_RANK,\n",
    "        -- p.IMD_QUINTILE, -- exclude as we are using normalised rank\n",
    "        -- Phenotype flags (coalesce to 0 for patients without records)\n",
    "        {phenotype_col}\n",
    "    FROM INTELLIGENCE_DEV.AI_CENTRE_FEATURE_STORE.PERSON_NEL_MASTER_INDEX p\n",
    "    INNER JOIN age_categories ac\n",
    "        ON p.PERSON_ID = ac.PERSON_ID\n",
    "    LEFT JOIN INTELLIGENCE_DEV.AI_CENTRE_FEATURE_STORE.PERSON_5YEAR_PHENOTYPE ph\n",
    "        ON p.PERSON_ID = ph.PERSON_ID\n",
    "    WHERE p.PATIENT_STATUS = 'ACTIVE'\n",
    "    AND p.LONDON_IMD_RANK IS NOT NULL -- Exclude missing IMD for demo run\n",
    "    AND p.INCLUDE_IN_LIST_SIZE_FLAG = 1\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = snowsesh.execute_query_to_df(query)\n",
    "        print(f\"Retreived columns: {df.columns}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving modeling data: {e}\")\n",
    "        raise e\n",
    "\n",
    "def prepare_modeling_data(\n",
    "        df,\n",
    "        phenotype_name\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Prepares data for modeling by encoding categorical variables and handling missing values.\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "            Input DataFrame\n",
    "        phenotype_name:\n",
    "            Name of the phenotype (now outcome column header)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of modeling DataFrame, metadata dict)\n",
    "    \"\"\"\n",
    "    df_prep = df.copy()\n",
    "\n",
    "    # Set reference categories for categorical variables\n",
    "    cat_refs = {\n",
    "        'ETHNIC_AIC_CATEGORY': 'Unknown',\n",
    "        'GENDER': 'Female',\n",
    "        'AGE_BAND': '45-54',  # Middle age as reference\n",
    "    }\n",
    "\n",
    "    # create dummy variables\n",
    "    for col, ref in cat_refs.items():\n",
    "        df_prep = pd.concat([df_prep, create_dummies(df_prep, col, ref)], axis=1)\n",
    "\n",
    "    # clean columns\n",
    "    column_mapping = {col: clean_column_name(col) for col in df_prep.columns}\n",
    "    df_prep = df_prep.rename(columns=column_mapping)\n",
    "\n",
    "    # create features\n",
    "    feature_cols = [col for col in df_prep.columns if col.startswith(tuple(cat_refs.keys()))]\n",
    "    for col in cat_refs:\n",
    "        feature_cols.remove(col) # Remove original columns after dummy creation\n",
    "    feature_cols.append('NORMALISED_IMD_RANK') # add other columns of interest here\n",
    "\n",
    "    # Create final modeling dataset\n",
    "    X = df_prep[feature_cols]\n",
    "    y = df_prep[phenotype_name]\n",
    "\n",
    "    # Combine into single dataframe\n",
    "    model_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Store column information\n",
    "    metadata = {\n",
    "        'feature_cols': feature_cols,\n",
    "        'outcome_col': phenotype_name,\n",
    "        'categorical_refs': cat_refs\n",
    "    }\n",
    "\n",
    "    # print basic checks (debug)\n",
    "    # print(\"Dataset Shape:\")\n",
    "    # print(model_df.shape)\n",
    "\n",
    "    # print(\"Metadata Dictionary:\")\n",
    "    # print(metadata)\n",
    "\n",
    "    # print(\"Outcome Distribution:\")\n",
    "    # outcome = metadata['outcome_col']\n",
    "    # print(model_df[outcome].value_counts(normalize=True))\n",
    "\n",
    "    # print(\"Missing Values:\")\n",
    "    # print(model_df.isnull().sum()[model_df.isnull().sum() > 0])\n",
    "\n",
    "    # model_df.to_csv('model_df.csv')\n",
    "\n",
    "    return model_df, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_models(\n",
    "        model_df,\n",
    "        metadata,\n",
    "        phenotype_name\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Fits logistic regression models with interaction terms and extracts odds ratios.\n",
    "    Interactions: ethnicity x age; ethnicity x deprivation\n",
    "\n",
    "    Args:\n",
    "        model_df:\n",
    "            Prepared modeling DataFrame\n",
    "        metadata:\n",
    "            Dictionary containing feature information\n",
    "        phenotype_name:\n",
    "            Name of the phenotype/outcome column\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Dictionary of fitted models\n",
    "        - DataFrame for effect modification plots\n",
    "        - DataFrame for stratified probability plots\n",
    "    \"\"\"\n",
    "\n",
    "    # list features for interactions\n",
    "    feature_cols = metadata['feature_cols']\n",
    "    ethnic_cols = [col for col in feature_cols if col.startswith('ETHNIC_AIC_CATEGORY_')]\n",
    "    age_cols = [col for col in feature_cols if col.startswith('AGE_BAND_')]\n",
    "    interaction_col = \"NORMALISED_IMD_RANK\"\n",
    "\n",
    "    # dyanmic formula generation including interaction terms\n",
    "    # e = ethnic subgropu\n",
    "    # a = age band\n",
    "    formula = f\"{phenotype_name} ~ {' + '.join(feature_cols)} + {' + '.join([f'{e}:{a}' for e in ethnic_cols for a in age_cols])} + {' + '.join([f'{e}:{interaction_col}' for e in ethnic_cols])}\"\n",
    "\n",
    "    # fit!\n",
    "    try:\n",
    "        model = logit(formula, data=model_df).fit(method='bfgs') ## more robust to low variance/singular matrix errors\n",
    "    except Exception as e:\n",
    "        print(f\"Formula that caused error: {formula}\")\n",
    "        raise e\n",
    "\n",
    "    odds_ratios = pd.DataFrame({\n",
    "        'odds_ratio': np.exp(model.params),\n",
    "        'lower_ci': np.exp(model.conf_int()[0]),\n",
    "        'upper_ci': np.exp(model.conf_int()[1])\n",
    "    })\n",
    "\n",
    "    pseudo_r_squared = model.prsquared\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'odds_ratios': odds_ratios,\n",
    "        'pseudo_r_squared': pseudo_r_squared,\n",
    "        'formula': formula # store the formula for debugging\n",
    "    }\n",
    "\n",
    "def print_model_summary(model_dict):\n",
    "    \"\"\"\n",
    "    Creates a detailed summary of the logistic regression model results.\n",
    "\n",
    "    Args:\n",
    "        model_dict:\n",
    "            Dictionary containing the fitted model and other information.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing formatted model results\n",
    "    \"\"\"\n",
    "    model = model_dict['model']\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Coefficient': model.params,\n",
    "        'Std Error': model.bse,\n",
    "        'z-value': model.tvalues,\n",
    "        'P>|z|': model.pvalues,\n",
    "        'OR': np.exp(model.params),\n",
    "        '[0.025': np.exp(model.conf_int()[0]),\n",
    "        '0.975]': np.exp(model.conf_int()[1])\n",
    "    })\n",
    "\n",
    "    summary_df = summary_df.round(4)\n",
    "\n",
    "    summary_df['Significance'] = ''\n",
    "    summary_df.loc[summary_df['P>|z|'] < 0.05, 'Significance'] = '*'\n",
    "    summary_df.loc[summary_df['P>|z|'] < 0.01, 'Significance'] = '**'\n",
    "    summary_df.loc[summary_df['P>|z|'] < 0.001, 'Significance'] = '***'\n",
    "\n",
    "    print(\"Model Fit Statistics:\")\n",
    "    print(f\"Number of observations: {model.nobs}\")\n",
    "    print(f\"Pseudo R-squared: {model.prsquared:.4f}\")\n",
    "    print(f\"Log-Likelihood: {model.llf:.4f}\")\n",
    "    print(f\"AIC: {model.aic:.4f}\")\n",
    "    print(f\"BIC: {model.bic:.4f}\")\n",
    "    print(\"Likelihood Ratio Test:\")\n",
    "    print(f\"Chi2: {model.llr:.4f}\")\n",
    "    print(f\"p-value: {model.llr_pvalue:.4f}\")\n",
    "\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_individual_risks(\n",
    "        df,\n",
    "        model_dict,\n",
    "        metadata\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Calculates individual risk scores using fitted model.\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "            Original dataframe containing patient data\n",
    "        model_dict:\n",
    "            Dictionary containing fitted model and results\n",
    "        metadata:\n",
    "            Dictionary containing feature information\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with original data plus risk scores and predictions\n",
    "    \"\"\"\n",
    "    model = model_dict['model']\n",
    "\n",
    "    # Create prediction dataframe wit same structure as training data\n",
    "    pred_df = prepare_modeling_data(df, metadata['outcome_col'])[0]\n",
    "\n",
    "    # return linear predictors /log-odds\n",
    "    linear_predictor = model.predict(pred_df, linear=True)\n",
    "\n",
    "    # return probabilities\n",
    "    probabilities = model.predict(pred_df)\n",
    "\n",
    "    # Add predictions to original dataframe\n",
    "    results_df = df.copy()\n",
    "    results_df['predicted_risk'] = probabilities\n",
    "    results_df['linear_predictor'] = linear_predictor\n",
    "\n",
    "    # Add binary prediction using 0.5 threshold (we can adjust this - I haven't calibrated)\n",
    "    results_df['predicted_case'] = (probabilities >= 0.5).astype(int)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def analyse_geographic_risk(\n",
    "        risk_df,\n",
    "        phenotype_name,\n",
    "        grouping_level='LSOA'):\n",
    "    \"\"\"\n",
    "    Aggregates risks and actual cases by geographic area.\n",
    "\n",
    "    Args:\n",
    "        risk_df:\n",
    "            DataFrame with individual risks and actual phenotype status\n",
    "        phenotype_name:\n",
    "            Name of the phenotype being analyzed\n",
    "        grouping_level:\n",
    "            Geographic level for aggregation (only LSOA for now)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with geographic risk analysis\n",
    "    \"\"\"\n",
    "    if grouping_level == 'LSOA':\n",
    "        geo_col = 'PATIENT_LSOA_2011'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported geographic level: {grouping_level}\")\n",
    "\n",
    "    # Aggregate by geographic area\n",
    "    geo_analysis = risk_df.groupby(geo_col).agg({\n",
    "        'predicted_risk': ['count', 'mean', 'sum'],  # sum gives expected number of cases\n",
    "        phenotype_name: ['sum'],  # actual cases\n",
    "        'PERSON_ID': 'count'  # = pop size\n",
    "    }).reset_index()\n",
    "\n",
    "    # flatten multi-level df into multipart column names\n",
    "    geo_analysis.columns = [\n",
    "        f\"{'' if col[0] == geo_col else col[0]}_{col[1]}\"\n",
    "        if col[1] != '' else col[0]\n",
    "        for col in geo_analysis.columns\n",
    "    ]\n",
    "\n",
    "    # summarise metrics\n",
    "    geo_analysis['expected_cases'] = geo_analysis['predicted_risk_sum']\n",
    "    geo_analysis['actual_cases'] = geo_analysis[f'{phenotype_name}_sum']\n",
    "    geo_analysis['population'] = geo_analysis['PERSON_ID_count']\n",
    "    geo_analysis['case_difference'] = geo_analysis['actual_cases'] - geo_analysis['expected_cases']\n",
    "    geo_analysis['standardized_difference'] = geo_analysis['case_difference'] / np.sqrt(geo_analysis['population'])\n",
    "\n",
    "    # Calculate 95% confidence intervals for the difference\n",
    "    geo_analysis['difference_ci_lower'] = geo_analysis['case_difference'] - (1.96 * np.sqrt(geo_analysis['population']))\n",
    "    geo_analysis['difference_ci_upper'] = geo_analysis['case_difference'] + (1.96 * np.sqrt(geo_analysis['population']))\n",
    "\n",
    "    # Flag areas with significant under-diagnosis\n",
    "    geo_analysis['significant_under_diagnosis'] = geo_analysis['difference_ci_upper'] < 0\n",
    "\n",
    "    return geo_analysis\n",
    "\n",
    "def summarise_risk_analysis(\n",
    "        geo_analysis,\n",
    "        phenotype_name\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Provides summary statistics of the geographic risk analysis.\n",
    "\n",
    "    Args:\n",
    "        geo_analysis:\n",
    "            Output from analyse_geographic_risk\n",
    "        phenotype_name:\n",
    "            Name of the phenotype being analyzed\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing summary statistics\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'phenotype': phenotype_name,\n",
    "        'total_population': int(geo_analysis['population'].sum()),\n",
    "        'total_actual_cases': int(geo_analysis['actual_cases'].sum()),\n",
    "        'total_expected_cases': int(round(geo_analysis['expected_cases'].sum())),\n",
    "        'total_case_difference': int(round(geo_analysis['case_difference'].sum())),\n",
    "        'areas_analyzed': len(geo_analysis),\n",
    "        'areas_under_diagnosed': int(geo_analysis['significant_under_diagnosis'].sum()),\n",
    "        'percent_areas_under_diagnosed': round(100 * geo_analysis['significant_under_diagnosis'].mean(), 1)\n",
    "    }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effect_modification_df(\n",
    "        model_dict,\n",
    "        metadata\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Creates effect modification dataframe from model coefficients showing odds ratios\n",
    "    across different strata.\n",
    "\n",
    "    Args:\n",
    "        model_dict:\n",
    "            Dictionary containing fitted model and results\n",
    "        metadata:\n",
    "            Dictionary containing feature information\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing effect modification results for age and IMD interactions\n",
    "    \"\"\"\n",
    "    model = model_dict['model']\n",
    "    records = []\n",
    "\n",
    "    # Extract coefficients and confidence intervals\n",
    "    coef = model.params\n",
    "    conf_int = model.conf_int()\n",
    "\n",
    "    # Get ethnic groups\n",
    "    ethnic_groups = [col.replace('ETHNIC_AIC_CATEGORY_', '').replace('[T.True]', '')\n",
    "                    for col in coef.index\n",
    "                    if col.startswith('ETHNIC_AIC_CATEGORY_') and ':' not in col]\n",
    "\n",
    "    # Get age bands\n",
    "    age_bands = [col.replace('AGE_BAND_', '').replace('[T.True]', '')\n",
    "                 for col in coef.index\n",
    "                 if col.startswith('AGE_BAND_') and ':' not in col]\n",
    "\n",
    "    # Process age band interactions\n",
    "    for ethnic in ethnic_groups:\n",
    "        ethnic_col = f'ETHNIC_AIC_CATEGORY_{ethnic}[T.True]'\n",
    "\n",
    "        # Get main effect/ci for ethnicity\n",
    "        ethnic_effect = coef[ethnic_col]\n",
    "        ethnic_ci = conf_int.loc[ethnic_col]\n",
    "\n",
    "        # calculate adjusted effect at each age band\n",
    "        for age in age_bands:\n",
    "            age_col = f'AGE_BAND_{age}[T.True]'\n",
    "            interaction_term = f\"{ethnic_col}:{age_col}\"\n",
    "\n",
    "            # adjusted effect of main + interaction)\n",
    "            main_age_effect = coef[age_col] if age_col in coef else 0\n",
    "            interaction_effect = coef[interaction_term] if interaction_term in coef else 0\n",
    "            total_effect = ethnic_effect + main_age_effect + interaction_effect\n",
    "\n",
    "            # confidence intervals\n",
    "            main_age_ci = conf_int.loc[age_col] if age_col in conf_int.index else [0, 0]\n",
    "            interaction_ci = conf_int.loc[interaction_term] if interaction_term in conf_int.index else [0, 0]\n",
    "            lower_ci = ethnic_ci[0] + main_age_ci[0] + interaction_ci[0]\n",
    "            upper_ci = ethnic_ci[1] + main_age_ci[1] + interaction_ci[1]\n",
    "\n",
    "            records.append({\n",
    "                'effect_modifier': 'age_band',\n",
    "                'modifier_value': age,\n",
    "                'ethnic_group': ethnic,\n",
    "                'odds_ratio': np.exp(total_effect),\n",
    "                'lower_ci': np.exp(lower_ci),\n",
    "                'upper_ci': np.exp(upper_ci)\n",
    "            })\n",
    "\n",
    "    # Process IMD interactions\n",
    "    imd_values = np.linspace(0, 1, 20)  # Take 20 points across IMD range\n",
    "\n",
    "    for ethnic in ethnic_groups:\n",
    "        ethnic_col = f'ETHNIC_AIC_CATEGORY_{ethnic}[T.True]'\n",
    "\n",
    "        # Get main effect/ci for ethnicity\n",
    "        ethnic_effect = coef[ethnic_col]\n",
    "        ethnic_ci = conf_int.loc[ethnic_col]\n",
    "\n",
    "        # Get IMD effect/ci\n",
    "        imd_effect = coef['NORMALISED_IMD_RANK']\n",
    "        imd_ci = conf_int.loc['NORMALISED_IMD_RANK']\n",
    "\n",
    "        # Get interaction effect\n",
    "        interaction_term = f\"{ethnic_col}:NORMALISED_IMD_RANK\"\n",
    "        interaction_effect = coef[interaction_term] if interaction_term in coef else 0\n",
    "        interaction_ci = conf_int.loc[interaction_term] if interaction_term in conf_int.index else [0, 0]\n",
    "\n",
    "        for imd in imd_values:\n",
    "            # imd and interaction effects as log-odds change per unit of imd\n",
    "            total_effect = ethnic_effect + (imd_effect * imd) + (interaction_effect * imd)\n",
    "\n",
    "            # confidence intervals\n",
    "            lower_ci = (ethnic_ci[0] + (imd_ci[0] * imd) + (interaction_ci[0] * imd))\n",
    "            upper_ci = (ethnic_ci[1] + (imd_ci[1] * imd) + (interaction_ci[1] * imd))\n",
    "\n",
    "            records.append({\n",
    "                'effect_modifier': 'imd_rank',\n",
    "                'modifier_value': imd,\n",
    "                'ethnic_group': ethnic,\n",
    "                'odds_ratio': np.exp(total_effect),\n",
    "                'lower_ci': np.exp(lower_ci),\n",
    "                'upper_ci': np.exp(upper_ci)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seaborn / matplotlib\n",
    "\n",
    "def plot_effect_modifications(\n",
    "        effect_df,\n",
    "        phenotype_name\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Creates two plots showing effect modification by age and IMD.\n",
    "    \"\"\"\n",
    "    sns.set_theme()\n",
    "    sns.set_palette(\"deep\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # age band plot\n",
    "    age_df = effect_df[effect_df['effect_modifier'] == 'age_band']\n",
    "\n",
    "    # # convert age bands to categorical for proper ordering\n",
    "    # age_order = ['0_minus_17', '18_minus_24', '25_minus_34', '35_minus_44',\n",
    "    #              '45_minus_54', '55_minus_64', '65_minus_74', '75_plus_']\n",
    "\n",
    "    for ethnic in age_df['ethnic_group'].unique():\n",
    "        ethnic_data = age_df[age_df['ethnic_group'] == ethnic]\n",
    "        ax1.plot(ethnic_data['modifier_value'], ethnic_data['odds_ratio'],\n",
    "                marker='o', label=ethnic)\n",
    "        ax1.fill_between(ethnic_data['modifier_value'],\n",
    "                        ethnic_data['lower_ci'],\n",
    "                        ethnic_data['upper_ci'],\n",
    "                        alpha=0.2)\n",
    "\n",
    "    ax1.set_title(f'Age Effect Modification for {phenotype_name}')\n",
    "    ax1.set_xlabel('Age Band')\n",
    "    ax1.set_ylabel('OR')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # IMD rank plot\n",
    "    imd_df = effect_df[effect_df['effect_modifier'] == 'imd_rank']\n",
    "\n",
    "    for ethnic in imd_df['ethnic_group'].unique():\n",
    "        ethnic_data = imd_df[imd_df['ethnic_group'] == ethnic].copy()\n",
    "        ethnic_data['modifier_value'] = pd.to_numeric(ethnic_data['modifier_value'])\n",
    "        ethnic_data = ethnic_data.sort_values('modifier_value')\n",
    "\n",
    "        ax2.plot(ethnic_data['modifier_value'], ethnic_data['odds_ratio'],\n",
    "                label=ethnic)\n",
    "        ax2.fill_between(ethnic_data['modifier_value'],\n",
    "                        ethnic_data['lower_ci'],\n",
    "                        ethnic_data['upper_ci'],\n",
    "                        alpha=0.2)\n",
    "\n",
    "    ax2.set_title(f'IMD Rank Effect Modification for {phenotype_name}')\n",
    "    ax2.set_xlabel('Normalized IMD Rank (0 = Most Deprived, 1 = Least Deprived)')\n",
    "    ax2.set_ylabel('OR')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # layout\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(1.02, 0.5), loc='center left', title=\"Ethnic Group\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "## altair - use this code in stremlit\n",
    "\n",
    "def plot_effect_modifications_altair(\n",
    "        effect_df,\n",
    "        phenotype_name\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Basic Altair plots showing effect modification by age and IMD.\n",
    "    \"\"\"\n",
    "    # Age band plot\n",
    "    age_df = effect_df[effect_df['effect_modifier'] == 'age_band']\n",
    "\n",
    "    age_chart = alt.Chart(age_df).mark_line().encode(\n",
    "        x='modifier_value:N',\n",
    "        y='odds_ratio:Q',\n",
    "        color='ethnic_group:N'\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=300,\n",
    "        title=f'Age Effect for {phenotype_name}'\n",
    "    )\n",
    "\n",
    "    # IMD plot\n",
    "    imd_df = effect_df[effect_df['effect_modifier'] == 'imd_rank'].copy()\n",
    "    imd_df['modifier_value'] = pd.to_numeric(imd_df['modifier_value'])\n",
    "\n",
    "    imd_chart = alt.Chart(imd_df).mark_line().encode(\n",
    "        x='modifier_value:Q',\n",
    "        y='odds_ratio:Q',\n",
    "        color='ethnic_group:N'\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=300,\n",
    "        title=f'IMD Effect for {phenotype_name}'\n",
    "    )\n",
    "\n",
    "    # combine plots\n",
    "    return alt.hconcat(age_chart, imd_chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "snowsesh = SnowflakeConnection()\n",
    "snowsesh.use_database(\"INTELLIGENCE_DEV\")\n",
    "snowsesh.use_schema(\"AI_CENTRE_FEATURE_STORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for a specific phenotype\n",
    "phenotype_name = \"HYPERTENSION\"\n",
    "df = get_modeling_data(snowsesh, phenotype_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modelling\n",
    "model_df, metadata = prepare_modeling_data(df, phenotype_name)\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit model\n",
    "model_results = fit_logistic_models(model_df, metadata, phenotype_name)\n",
    "model_summary = print_model_summary(model_results)\n",
    "\n",
    "print(\"Model Summary:\")\n",
    "print(model_summary)\n",
    "\n",
    "print(\"Odds Ratios:\")\n",
    "print(model_results['odds_ratios'])\n",
    "\n",
    "print(\"Pseudo R-squared:\")\n",
    "print(model_results['pseudo_r_squared'])\n",
    "\n",
    "print(\"Formula:\")\n",
    "print(model_results['formula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_df = calculate_individual_risks(df, model_results, metadata)\n",
    "geo_analysis = analyse_geographic_risk(risk_df, phenotype_name)\n",
    "\n",
    "summary_stats = summarise_risk_analysis(geo_analysis, phenotype_name)\n",
    "\n",
    "print(f\"Summary for {phenotype_name}:\")\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_df = create_effect_modification_df(model_results, metadata)\n",
    "effect_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "fig = plot_effect_modifications(effect_df, \"Hypertension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.renderers.enable('default')\n",
    "chart = plot_effect_modifications_altair(effect_df, \"Hypertension\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN (LOOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Creates effect modification analysis for all phenotypes and combines into single dataset\n",
    "    Performs risk analysis and prediction for all phenotypes and combines into single dataset\n",
    "    Uploads both to Snowflake\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "\n",
    "    try:\n",
    "        effect_dfs = []\n",
    "        risk_dfs = []\n",
    "\n",
    "        # Process each phenotype\n",
    "        for phenotype in tqdm(PHENOTYPES_OF_INTEREST.keys(), desc=\"Processing phenotypes\"):\n",
    "            print(f\"Now modelling {phenotype}\")\n",
    "\n",
    "            # Get and process data\n",
    "            df = get_modeling_data(snowsesh, phenotype)\n",
    "            model_df, metadata = prepare_modeling_data(df, phenotype)\n",
    "            model_results = fit_logistic_models(model_df, metadata, phenotype)\n",
    "\n",
    "            # Generate and store effects with phenotype label\n",
    "            effect_df = create_effect_modification_df(model_results, metadata)\n",
    "            effect_df['phenotype'] = phenotype\n",
    "            effect_dfs.append(effect_df)\n",
    "            print(f\"{phenotype} effects appended\")\n",
    "\n",
    "            # Generate and store predicted risks with phenotype label\n",
    "            risk_df = calculate_individual_risks(df, model_results, metadata)\n",
    "            geo_analysis = analyse_geographic_risk(risk_df, phenotype)\n",
    "            geo_analysis['phenotype'] = phenotype\n",
    "            key_cols = [\n",
    "                'PATIENT_LSOA_2011',\n",
    "                'phenotype',\n",
    "                'population',\n",
    "                'actual_cases',\n",
    "                'expected_cases',\n",
    "                'case_difference',\n",
    "                'standardized_difference',\n",
    "                'significant_under_diagnosis'\n",
    "            ]\n",
    "            risk_dfs.append(geo_analysis[key_cols])\n",
    "\n",
    "        # Combine all effects and save\n",
    "        phenotype_effects = pd.concat(effect_dfs, ignore_index=True)\n",
    "        #phenotype_effects.to_csv('phenotype_effects.csv', index=False)\n",
    "        print(f\"Saved combined effects for {len(PHENOTYPES_OF_INTEREST)} phenotypes\")\n",
    "\n",
    "        # Combine all calculated risks and save\n",
    "        combined_risk_analysis = pd.concat(risk_dfs, ignore_index=True)\n",
    "        #combined_risk_analysis.to_csv('risk_analysis.csv', index=False)\n",
    "        print(f\"Saved combined risk analysis for {len(PHENOTYPES_OF_INTEREST)} phenotypes\")\n",
    "\n",
    "        # Create effect visualisations\n",
    "        for phenotype in PHENOTYPES_OF_INTEREST.keys():\n",
    "            try:\n",
    "                phenotype_data = phenotype_effects[phenotype_effects['phenotype'] == phenotype]\n",
    "                fig = plot_effect_modifications(phenotype_data, phenotype)\n",
    "                print(f\"SHOWING: {phenotype}\")\n",
    "                plt.show()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main process: {e}\")\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowsesh.load_csv_as_table(\n",
    "#     csv_path='phenotype_effects.csv',\n",
    "#     table_name='PHENOTYPE_ADJUSTED_EFFECTS',\n",
    "#     mode=\"overwrite\"\n",
    "# )\n",
    "\n",
    "# snowsesh.load_csv_as_table(\n",
    "#     csv_path='risk_analysis.csv',\n",
    "#     table_name='PHENOTYPE_GEOSPATIAL_RISK',\n",
    "#     mode=\"overwrite\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
