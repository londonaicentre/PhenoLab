{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from phmlondon.snow_utils import SnowflakeConnection\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, OPTICS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "conn = SnowflakeConnection()\n",
    "conn.use_database(\"INTELLIGENCE_DEV\")\n",
    "conn.use_schema(\"AI_CENTRE_DEV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_frequency_cutoff = 100\n",
    "sample_size_for_clustering = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_patient = conn.session.sql(\"\"\"\n",
    "select o.patient_id, o.core_concept_id, count(o.core_concept_id) as code_count, c.name\n",
    "from prod_dwh.analyst_primary_care.observation as o\n",
    "join prod_dwh.analyst_primary_care.concept as c\n",
    "on o.core_concept_id = c.dbid\n",
    "where c.name like '%(disorder)%' \n",
    "and o.clinical_effective_date >= DATEADD(YEAR, -10, CURRENT_DATE)\n",
    "group by o.patient_id, o.core_concept_id, c.name;\n",
    "\"\"\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_patient.sort_values(by=\"CODE_COUNT\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_code_counts = counts_by_patient.groupby([\"CORE_CONCEPT_ID\", \"NAME\"]).agg({\"CODE_COUNT\": \"sum\"}).sort_values(by=\"CODE_COUNT\", ascending=False).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_code_counts.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_code_counts.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any codes that haven't occured in at least 100 patients - should later experiment with removing this step\n",
    "code_occurences_by_patient = counts_by_patient['CORE_CONCEPT_ID'].value_counts()\n",
    "codes_to_include = code_occurences_by_patient[code_occurences_by_patient > code_frequency_cutoff].index\n",
    "counts_by_patient_filtered = counts_by_patient[counts_by_patient['CORE_CONCEPT_ID'].isin(codes_to_include)]\n",
    "counts_by_patient_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log normalise\n",
    "counts_by_patient_filtered = counts_by_patient_filtered.copy()\n",
    "counts_by_patient_filtered['LOG_CODE_COUNT'] = counts_by_patient_filtered['CODE_COUNT'].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_patient_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients = counts_by_patient_filtered['PATIENT_ID'].nunique()\n",
    "num_concepts = counts_by_patient_filtered['CORE_CONCEPT_ID'].nunique()\n",
    "print(f\"Unique PATIENT_IDs: {num_patients}\")\n",
    "print(f\"Unique CORE_CONCEPT_IDs: {num_concepts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of data points by random selection\n",
    "counts_by_patient_filtered = counts_by_patient_filtered.sample(sample_size_for_clustering)\n",
    "len(counts_by_patient_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.Categorical(counts_by_patient_filtered['PATIENT_ID'])\n",
    "concepts = pd.Categorical(counts_by_patient_filtered['CORE_CONCEPT_ID'])\n",
    "reshaped_data = csr_matrix(\n",
    "    (counts_by_patient_filtered['LOG_CODE_COUNT'], (patients.codes, concepts.codes))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshaped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dimensionality reduction using truncated SVD (better than PCA for sparse matrices)\n",
    "n_components = 50\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = svd.fit_transform(reshaped_data)\n",
    "print(f\"Explained variance ratio: {svd.explained_variance_ratio_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_by_optics = OPTICS(min_samples=10, max_eps=50).fit_predict(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_by_dbscan = DBSCAN(eps=50, min_samples=10).fit_predict(X_reduced)\n",
    "\n",
    "# dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "# dbscan_labels = dbscan.fit_predict(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_by_knn = KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_clusters = pd.DataFrame({\n",
    "    'PATIENT_ID': patients.categories,  # Original PATIENT_IDs\n",
    "    'CLUSTER_LABEL': np.array(cluster_labels_by_dbscan)      # Corresponding cluster labels\n",
    "})\n",
    "patient_clusters.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data = counts_by_patient_filtered.merge(patient_clusters, on='PATIENT_ID', how='left')\n",
    "print(clustered_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensions to 2 using UMAP\n",
    "num_samples = 200\n",
    "random_indices = np.random.choice(X_reduced.shape[0], num_samples, replace=False)\n",
    "sample_of_X_reduced = X_reduced[random_indices]\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_vis = reducer.fit_transform(sample_of_X_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = cluster_labels_by_dbscan[random_indices] != -1\n",
    "X_filtered = X_vis[mask] \n",
    "dbscan_labels_filtered = cluster_labels_by_dbscan[random_indices][mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN memory issues\n",
    "# https://stackoverflow.com/questions/44131411/dbscan-handling-big-data-crashes-and-memory-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_clusters = len(set(cluster_labels_by_dbscan) - {-1})\n",
    "\n",
    "print(f\"Number of clusters found: {n_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_filtered[:, 0], X_filtered[:, 1], c=dbscan_labels_filtered, cmap='viridis', s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- to do  -->\n",
    "code in thresholds\n",
    "seed random number for plot\n",
    "check works fullsize\n",
    "details on plot?\n",
    "explainability\n",
    "modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "most_popular_code = {patient: reshaped_data.loc[patient].idxmax() for patient in reshaped_data.index}\n",
    "clustered_data['most_popular_code'] = clustered_data['PATIENT_ID'].map(most_popular_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_code_for_sql = \",\".join(map(str,clustered_data['most_popular_code']))\n",
    "print(most_popular_code_for_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [most_popular_code_names.loc[most_popular_code_names['DBID'] == code]['NAME'] \n",
    "         for code in clustered_data['most_popular_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in range(n_clusters):\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    print(counts_by_patient_labeled.loc[counts_by_patient_labeled['CLUSTER_LABEL'] == cluster, 'most_popular_code_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
